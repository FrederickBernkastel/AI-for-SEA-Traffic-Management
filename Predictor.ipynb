{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given CSV file of past 14 days data, predict next 5 periods for all latt long and save to csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import Geohash\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "\n",
    "DATA_PATH = os.getcwd() + \"/Data/test.csv\"\n",
    "OUTPUT_CSV_PATH = os.getcwd() + '/Predict/output.csv'\n",
    "\n",
    "\n",
    "# Load global variables\n",
    "with open(\"Model/long_to_idx_dic.pkl\",\"rb\") as f:\n",
    "    long_to_idx_dic = pickle.load(f)\n",
    "with open(\"Model/latt_to_idx_dic.pkl\",\"rb\") as f:\n",
    "    latt_to_idx_dic = pickle.load(f)\n",
    "with open(\"Model/xgb_model.model\",\"rb\") as f:\n",
    "    gbm = pickle.load(f)\n",
    "with open(\"Model/lgb_model.model\",\"rb\") as f:\n",
    "    lgbm = pickle.load(f)\n",
    "\n",
    "latt_vals = sorted([item for item in latt_to_idx_dic.keys()])\n",
    "long_vals = sorted([item for item in long_to_idx_dic.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_data(data_path=DATA_PATH):\n",
    "    \"\"\"Parses csv file into numpy array\"\"\"\n",
    "    day_periods = 24*4\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Add latt and long columns\n",
    "    df['latt'] = df['geohash6'].apply(lambda x: Geohash.decode(x)[0])\n",
    "    df['long'] = df['geohash6'].apply(lambda x: Geohash.decode(x)[1])\n",
    "    last_day = max(df['day'].unique())\n",
    "    last_period = max(['0'+item if len(item.split(':')[0])<2 else item for item in df[df['day']==last_day]['timestamp'].unique()])\n",
    "    last_hour,last_minutes = map(int,last_period.split(':'))\n",
    "    last_day_period = last_hour*4 + last_minutes//15\n",
    "\n",
    "    # Populate raw demand data onto np array of shape (day_time_periods,latt,long)\n",
    "    demand_data = []\n",
    "    for day in range(last_day-8,last_day+1):\n",
    "        filtered_day = df[df['day'] == day]\n",
    "        print(\"Loading Day %d\"%(day),end='\\r')\n",
    "        hours_gen = range(last_hour+1) if day==last_day else range(24)\n",
    "        for hour in hours_gen:\n",
    "            for minute in \"0 15 30 45\".split():\n",
    "                if day==last_day and hour==last_hour and int(minute)>last_minutes:\n",
    "                    break\n",
    "\n",
    "                timestamp = \"%d:%s\"%(hour,minute)\n",
    "                a = np.zeros((len(latt_vals),len(long_vals)))\n",
    "                filtered_time = filtered_day[filtered_day['timestamp']==timestamp]\n",
    "\n",
    "                for idx,item in filtered_time[['latt','long','demand']].iterrows():\n",
    "                    latt,long,demand = item\n",
    "                    latt_idx = latt_to_idx_dic[latt]\n",
    "                    long_idx = long_to_idx_dic[long]\n",
    "                    a[latt_idx,long_idx] = demand\n",
    "                demand_data.append(a)\n",
    "    demand_data = np.stack(demand_data,axis=0)\n",
    "    \n",
    "    # Check if enough data was provided\n",
    "    assert demand_data.shape[0] >= 7*day_periods+3\n",
    "    \n",
    "    return demand_data, (last_day,last_day_period)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def increase_time_period(day,day_period,increase_by=1):\n",
    "    \"\"\"Calculates value of day and day period after an increase in day_period\"\"\"\n",
    "    day_periods = 24*4\n",
    "    day_period += increase_by\n",
    "    return day + day_period//day_periods, day_period%day_periods\n",
    "\n",
    "\n",
    "def add_df_entries(df,pred_arr,day,day_period):\n",
    "    \"\"\"\n",
    "    Adds entries from a numpy array into an existing pandas df, and returns the combined df\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas Dataframe\n",
    "        Pandas dataframe of timestamps, day, geohash6 and demand data\n",
    "    pred_arr: Numpy Array\n",
    "        Numpy array of predicted demand with the shape (n_latt,n_long), where\n",
    "            n_latt refers to the number of lattitude values\n",
    "            n_long refers to the number of longitude values\n",
    "    day: int\n",
    "        Day value of the predicted numpy array\n",
    "    day_period: int\n",
    "        Day Period of the predicted numpy array. Valid values are 0-95 inclusive.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Dataframe\n",
    "        Pandas dataframe of combined numpy and df provided\n",
    "    \"\"\"\n",
    "    new_rows = []\n",
    "    time = \"%d:%d\"%(day_period//4,(day_period%4)*15)\n",
    "    for latt in latt_vals:\n",
    "        latt_idx = latt_to_idx_dic[latt]\n",
    "        for long in long_vals:\n",
    "            long_idx = long_to_idx_dic[long]\n",
    "            demand = pred_arr[latt_idx,long_idx]\n",
    "            # Similar to training data, do not include 0 entries \n",
    "            if demand <=10e-6:\n",
    "                continue\n",
    "            geohash6 = Geohash.encode(latt,long,precision=6)\n",
    "            new_rows.append({\n",
    "                'geohash6': geohash6,\n",
    "                'day': day,\n",
    "                'timestamp': time,\n",
    "                'demand': demand\n",
    "            })\n",
    "            \n",
    "    \n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "    return df.append(new_rows_df,sort=False)\n",
    "\n",
    "\n",
    "def extract_features(data,day,day_period):\n",
    "    \"\"\"\n",
    "    Extracts features from numpy array of demand, for testing\n",
    "    Numpy array should only contain data for the previous 7 days + 3 day_periods\n",
    "    It is expected that model data is present in the /Model folder before running\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Numpy array\n",
    "        3D Numpy array of demand data, with the shape (n_periods, n_latt, n_long), where\n",
    "            n_periods refers to the number of 15-minute periods\n",
    "            n_latt refers to the number of lattitude values\n",
    "            n_long refers to the number of longitude values\n",
    "    day: int\n",
    "        Day value of the period to be predicted\n",
    "    day_period: int\n",
    "        Day Period to be predicted. Valid values are 0-95 inclusive.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numpy Array\n",
    "        4D Numpy array of features, with the shape (n_features, 1, n_latt, n_long), where\n",
    "            n_features refers to the number of features for each data sample\n",
    "            n_latt refers to the number of lattitude values\n",
    "            n_long refers to the number of longitude values\n",
    "    \"\"\"\n",
    "    # Load normalizers\n",
    "    with open(\"Model/all_meta_features.pkl\",\"rb\") as f:\n",
    "        all_meta_features = pickle.load(f)\n",
    "    day_periods = 24*4\n",
    "    all_features = []\n",
    "    n_periods = data.shape[0]\n",
    "    \n",
    "    # Normal Features\n",
    "    # Current day features\n",
    "    for X in [-7,-6,-5,-4,-3,-2,-1]:\n",
    "        all_features.append(data[X:X+1+n_periods,:,:])\n",
    "    # Previous day features\n",
    "    for D in [-7,-4,-3,-2,-1]:\n",
    "        for X in [-3,-2,-1,0,1,2,3,4]:\n",
    "            all_features.append(data[D*day_periods + X:D*day_periods + X + 1 + n_periods,:,:])\n",
    "    \n",
    "    # Time period features\n",
    "    day_periods_arr = np.arange(day_periods)/day_periods\n",
    "    \n",
    "    sin_arr = np.sin(2*np.pi*day_periods_arr)\n",
    "    sin_arr = sin_arr[day_period:day_period+1]\n",
    "    all_features.append(sin_arr[:,None,None]*np.ones((1,1,data.shape[2]))*np.ones((1,data.shape[1],1)))\n",
    "    \n",
    "    cos_arr = np.cos(2*np.pi*day_periods_arr)\n",
    "    cos_arr = cos_arr[day_period:day_period+1]\n",
    "    all_features.append(cos_arr[:,None,None]*np.ones((1,1,data.shape[2]))*np.ones((1,data.shape[1],1)))\n",
    "    \n",
    "    # Weekday period features\n",
    "    weekday_periods_arr = np.arange(7)/7\n",
    "    day = day % 7\n",
    "    \n",
    "    sin_arr = np.sin(2*np.pi*weekday_periods_arr)\n",
    "    sin_arr = sin_arr[day : day+1]\n",
    "    all_features.append(sin_arr[:,None,None]*np.ones((1,1,data.shape[2]))*np.ones((1,data.shape[1],1)))\n",
    "    \n",
    "    cos_arr = np.cos(2*np.pi*weekday_periods_arr)\n",
    "    cos_arr = cos_arr[day : day+1]\n",
    "    all_features.append(cos_arr[:,None,None]*np.ones((1,1,data.shape[2]))*np.ones((1,data.shape[1],1)))\n",
    "    \n",
    "    # Geospatial features\n",
    "    latt = (np.arange(data.shape[1])[:,None]/data.shape[1]) * np.ones(data.shape[2])[None,:]\n",
    "    long = np.ones(data.shape[1])[:,None] * (np.arange(data.shape[2])[None,:]/data.shape[2])\n",
    "    all_features.extend([latt[None,:,:],long[None,:,:]])\n",
    "    \n",
    "    # Aggregrated demand features by location\n",
    "    all_features.append(all_meta_features['agg_location'])\n",
    "\n",
    "    \n",
    "    # Aggregrated demand features by time period\n",
    "    full_agg_arr = np.sum(np.sum(data,axis=1,keepdims=True),axis=2,keepdims=True).squeeze()\n",
    "    divisor = all_meta_features['agg_period']\n",
    "    divisor = np.tile(divisor, reps=full_agg_arr.shape[0]//96+2)\n",
    "    divisor_start_idx = (day_period-full_agg_arr.shape[0])%96\n",
    "    divisor = divisor[divisor_start_idx:divisor_start_idx+full_agg_arr.shape[0]]\n",
    "    \n",
    "    full_agg_arr /= divisor\n",
    "    # Current day aggregrated demand\n",
    "    for X in [-4,-3,-2,-1]:\n",
    "        agg_arr = full_agg_arr[X+n_periods:X+1+n_periods,None,None]\n",
    "        all_features.append(agg_arr*np.ones((1,data.shape[1],data.shape[2])))\n",
    "\n",
    "    # Past day aggregrated demand\n",
    "    for D in [-7]:\n",
    "        for X in [-1,0,1]:\n",
    "            agg_arr = full_agg_arr[D*day_periods + X:D*day_periods + X+1+n_periods,None,None]\n",
    "            all_features.append(agg_arr*np.ones((1,data.shape[1],data.shape[2])))\n",
    "\n",
    "    return np.stack(all_features,axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(demand_data,last_day_tup):\n",
    "    \"\"\"\n",
    "    Predicts T+1 to T+5 demand given demand data until period T, and saves prediction as a csv file in OUTPUT_CSV_PATH \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    demand_data : Numpy array\n",
    "        3D Numpy array of demand data, with the shape (n_periods, n_latt, n_long), where\n",
    "            n_periods refers to the number of 15-minute periods\n",
    "            n_latt refers to the number of lattitude values\n",
    "            n_long refers to the number of longitude values\n",
    "    last_day_tup: Tuple\n",
    "        Tuple of (day, day_period) for the most recent day and day period in the demand data\n",
    "    \"\"\"\n",
    "    last_day, last_day_period = last_day_tup\n",
    "    day_periods = 24*4\n",
    "    col_names = \"geohash6 day timestamp demand\".split()\n",
    "    output_df = pd.DataFrame(columns = col_names)\n",
    "    zero_demand = np.load('Model/zero_demand.npy')\n",
    "    \n",
    "    # Predict next value 5 times for all latt and long\n",
    "    for _ in range(5):\n",
    "        # Extract relevant from demand data\n",
    "        last_day,last_day_period = increase_time_period(last_day,last_day_period)\n",
    "        input_demand = demand_data[-7*day_periods-3:,:,:]\n",
    "        input_demand = extract_features(input_demand,last_day,last_day_period)\n",
    "        input_demand = input_demand.reshape((input_demand.shape[0],-1)).T\n",
    "\n",
    "        # Predict\n",
    "        pred = (gbm.predict(input_demand).squeeze() + lgbm.predict(input_demand).squeeze())/2\n",
    "        pred = pred.clip(0,1)\n",
    "        pred = pred.reshape((len(latt_vals),len(long_vals)))\n",
    "        pred[zero_demand[0],zero_demand[1]] = 0. # Set geocode locations which are not in training set to zero\n",
    "        demand_data = np.concatenate((demand_data,pred[None,:,:]),axis=0)\n",
    "\n",
    "        # Store output in df\n",
    "        output_df = add_df_entries(output_df,pred,last_day,last_day_period)\n",
    "        \n",
    "    # Save output to file\n",
    "    output_df.to_csv(OUTPUT_CSV_PATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    demand_data, last_day_tup = parse_raw_data()\n",
    "    predict(demand_data,last_day_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Day 61\r"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
